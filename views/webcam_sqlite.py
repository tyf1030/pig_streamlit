import streamlit as st
from streamlit_webrtc import webrtc_streamer
import av
import cv2
import threading
import time
import queue
import random
import os
import shutil
from collections import deque
import numpy as np
import copy
import traceback
import sqlite3
import datetime 

# å¼•å…¥é¡¹ç›®é…ç½®
import config 
from utils.model_loader import load_ar_model_cached, load_od_model_cached
from backend.processors import filter_and_analyze_tracking_results, process_video_regions
from backend.inference import inference_recognizer_simplified
import logging
# ==========================================
# 0. è¾…åŠ©å·¥å…·å‡½æ•°
# ==========================================s

logger = logging.getLogger("Views.StreamAnalyzer")
def extract_yolo_data_to_cpu(yolo_results: list) -> list:
    """
    å°† YOLO ç»“æœè½¬æ¢ä¸º CPU ä¸Šçš„ numpy å­—å…¸åˆ—è¡¨ï¼Œä¾¿äºè·¨çº¿ç¨‹ä¼ é€’ã€‚
    """
    cpu_data = []
    for res in yolo_results:
        n_boxes = len(res.boxes)
        if res.boxes.id is not None:
            ids = res.boxes.id.cpu().numpy()
        else:
            if n_boxes > 0:
                ids = np.full((n_boxes,), -1.0) 
            else:
                ids = np.array([])

        frame_data = {
            "boxes": res.boxes.xyxy.cpu().numpy(),
            "conf": res.boxes.conf.cpu().numpy(),
            "cls": res.boxes.cls.cpu().numpy(),
            "id": ids 
        }
        cpu_data.append(frame_data)
    return cpu_data

def save_uploaded_od_model(uploaded_file):
    if uploaded_file is None: return
    os.makedirs(config.OD_MODEL_DIR, exist_ok=True)
    save_path = os.path.join(config.OD_MODEL_DIR, uploaded_file.name)
    with open(save_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    logger.info(f"âœ… OD æ¨¡å‹å·²ä¿å­˜: {uploaded_file.name}")
    st.toast(f"âœ… OD æ¨¡å‹å·²ä¿å­˜: {uploaded_file.name}")

def save_uploaded_ar_model(uploaded_files):
    if not uploaded_files: return
    py_file = next((f for f in uploaded_files if f.name.endswith('.py')), None)
    pth_file = next((f for f in uploaded_files if f.name.endswith('.pth')), None)
    
    if not py_file or not pth_file:
        logger.error("ä¸Šä¼ æ–‡ä»¶æ ¼å¼é”™è¯¯")
        st.error("âŒ å¿…é¡»è¦åŒæ—¶ä¸Šä¼  .py å’Œ .pth æ–‡ä»¶")
        return

    py_name = os.path.splitext(py_file.name)[0]
    pth_name = os.path.splitext(pth_file.name)[0]
    if py_name != pth_name:
        logger.error("æ–‡ä»¶åä¸ä¸€è‡´: {py_name}.py vs {pth_name}.pth")
        st.error(f"âŒ æ–‡ä»¶åä¸ä¸€è‡´: {py_name}.py vs {pth_name}.pth")
        return

    model_dir = os.path.join(config.AR_MODEL_DIR, py_name)
    os.makedirs(model_dir, exist_ok=True)
    
    with open(os.path.join(model_dir, py_file.name), "wb") as f:
        f.write(py_file.getbuffer())
    with open(os.path.join(model_dir, pth_file.name), "wb") as f:
        f.write(pth_file.getbuffer())

    logger.info(f"âœ… AR æ¨¡å‹å·²ä¿å­˜: {uploaded_file.name}")  
    st.toast(f"âœ… AR æ¨¡å‹å·²ä¿å­˜è‡³: {model_dir}")

# === ä¿®æ”¹ï¼šOnlineVideoData æ”¯æŒ 16 å¸§æ’å€¼ä¸ç»Ÿä¸€æ•°æ®ç”Ÿæˆ ===
class OnlineVideoData:
    def __init__(self, frames:list, timestamps:list):
        self.frames = frames # list of np.array (16)
        self.timestamps = timestamps # list of datetime (16)
        
        # OD åŸå§‹æ•°æ® (Frame-by-Frame)
        self.boxes = []
        self.conf = []
        self.cls = []
        self.id = []
        
        # AR ç»“æœæ•°æ®
        self.ar_box = [] # ç”¨äºæ¨ç†çš„ input box list
        self.ar_id = []  # å‚ä¸ AR çš„ Track ID
        self.ar_conf = [] # AR ç»“æœç½®ä¿¡åº¦
        self.ar_cls = []  # AR ç»“æœç±»åˆ«ç´¢å¼•
    
    def load_cpu_data(self, cpu_results: list):
        for result in cpu_results:
            self.boxes.append(result["boxes"])
            self.conf.append(result["conf"])
            self.cls.append(result["cls"])
            self.id.append(result["id"])
    
    def from_mmaction_result(self, mm_res:list):
        for result in mm_res:
            scores = result.pred_score.cpu().numpy()
            self.ar_conf.append(np.max(scores))
            self.ar_cls.append(np.argmax(scores))
    
    def _interpolate_bbox(self, bbox_seq):
        """ç®€å•çš„çº¿æ€§æ’å€¼ï¼Œå¡«å…… None çš„ bbox"""
        # bbox_seq: list of [bbox or None] with length 16
        seq_len = len(bbox_seq)
        
        # 1. æ‰¾åˆ°æ‰€æœ‰éç©ºçš„ç´¢å¼•
        valid_indices = [i for i, b in enumerate(bbox_seq) if b is not None]
        
        if not valid_indices:
            # å¦‚æœå…¨æ˜¯ç©ºï¼Œè¿”å›å…¨ 0
            return [np.zeros(4) for _ in range(seq_len)]
            
        # 2. å‰å‘å¡«å…… (Fill Forward)
        for i in range(valid_indices[0]):
            bbox_seq[i] = bbox_seq[valid_indices[0]]
            
        # 3. åå‘å¡«å…… (Fill Backward)
        for i in range(valid_indices[-1] + 1, seq_len):
            bbox_seq[i] = bbox_seq[valid_indices[-1]]
            
        # 4. ä¸­é—´æ’å€¼
        for k in range(len(valid_indices) - 1):
            start_idx = valid_indices[k]
            end_idx = valid_indices[k+1]
            steps = end_idx - start_idx
            
            start_box = bbox_seq[start_idx]
            end_box = bbox_seq[end_idx]
            
            for step in range(1, steps):
                alpha = step / steps
                interpolated_box = start_box * (1 - alpha) + end_box * alpha
                bbox_seq[start_idx + step] = interpolated_box
                
        return bbox_seq

    def get_unified_db_data(self, action_classes, username):
        """
        [é‡æ„ç‰ˆ] ç”Ÿæˆç»Ÿä¸€çš„æ•°æ®åº“å†™å…¥æ•°æ®ã€‚
        ç­–ç•¥ï¼š
        1. åŒ…å«æ‰€æœ‰åŸå§‹ OD æ£€æµ‹ç»“æœ (æ¯ä¸€å¸§çš„æ¯ä¸ªæ¡†éƒ½å†™å…¥)
        2. åŒ…å« AR ç»“æœ (ä½¿ç”¨ç®€å•å¤åˆ¶ç­–ç•¥ï¼Œå°† 4 ä¸ªå¹¶é›†æ¡†æ‰©å±•ä¸º 16 å¸§æ•°æ®)
        """
        db_rows = []
        
        # è·å–å›¾åƒå°ºå¯¸
        img_h, img_w = 0, 0
        if self.frames:
            img_h, img_w = self.frames[0].shape[:2]

        # ==========================================
        # éƒ¨åˆ† 1: å†™å…¥æ‰€æœ‰ OD (ç›®æ ‡æ£€æµ‹) åŸå§‹ç»“æœ
        # ==========================================
        # è¿™ä¸€æ­¥ä¸ç®¡æ˜¯å¦è¢« AR é€‰ä¸­ï¼Œåªè¦ YOLO çœ‹åˆ°äº†ï¼Œå°±è®°å½•ä¸‹æ¥
        for i in range(len(self.frames)):
            frame_boxes = self.boxes[i]
            frame_confs = self.conf[i]
            frame_clss = self.cls[i]
            
            # è·å–å½“å‰å¸§çš„æ—¶é—´æˆ³
            ts_str = self.timestamps[i].strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
            
            for j in range(len(frame_boxes)):
                box = frame_boxes[j]
                conf = float(frame_confs[j])
                cls_id = int(frame_clss[j])
                
                # æ ‡è®°ä¸ºåŸå§‹æ£€æµ‹ï¼Œä¿ç•™åŸå§‹ç±»åˆ«ID
                # æ ¼å¼ç¤ºä¾‹: "OD_Raw:0" (0é€šå¸¸æ˜¯Person)
                category = f"OD_Raw:{cls_id}" 

                db_rows.append((
                    username,
                    "webcam_stream", img_h, img_w, category,
                    float(box[0]), float(box[1]), float(box[2]), float(box[3]),
                    conf, ts_str
                ))

        # ==========================================
        # éƒ¨åˆ† 2: å†™å…¥ AR (è¡Œä¸ºè¯†åˆ«) ç»“æœ
        # ==========================================
        # è¿™ä¸€æ­¥é’ˆå¯¹è¯†åˆ«å‡ºçš„è¡Œä¸ºï¼Œç”Ÿæˆå¯¹åº”çš„ 16 æ¡è½¨è¿¹è®°å½•
        for idx in range(len(self.ar_id)):
            # 1. è·å–è¡Œä¸ºç±»åˆ«åç§°
            cls_idx = self.ar_cls[idx]
            if cls_idx < len(action_classes):
                action_name = action_classes[cls_idx]
            else:
                action_name = f"Action_{cls_idx}"
            
            confidence = float(self.ar_conf[idx])
            
            # 2. è·å–è¯¥è¡Œä¸ºå¯¹åº”çš„ 4 ä¸ªæ—¶é—´æ®µçš„æ¡† (List of 4 arrays)
            # æ³¨æ„ï¼šè¿™æ˜¯ filter_and_analyze_tracking_results ç”Ÿæˆçš„å¹¶é›†æ¡†
            four_boxes = self.ar_box[idx] 
            
            # 3. éå† 4 ä¸ªæ—¶é—´æ®µ (Segment)
            for segment_idx in range(4):
                # è·å–å½“å‰æ®µçš„æ¡† (ä»£è¡¨è¿™ 4 å¸§çš„å¹¶é›†èŒƒå›´)
                box = four_boxes[segment_idx]
                
                # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§ï¼šå¦‚æœè¯¥æ®µæ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡ (å¯èƒ½æ˜¯ NaN)ï¼Œåˆ™è·³è¿‡ä¸å†™å…¥
                # è¿™æ ·æ•°æ®åº“é‡Œå°±ä¸ä¼šæœ‰åƒåœ¾æ•°æ®
                if box is None or np.isnan(box).any():
                    continue

                # 4. ç®€å•å¤åˆ¶ç­–ç•¥ï¼šå°†è¿™ 1 ä¸ªæ¡†åº”ç”¨åˆ°è¯¥æ®µçš„ 4 å¸§ä¸Š
                start_frame = segment_idx * 4
                end_frame = start_frame + 4
                
                for i in range(start_frame, end_frame):
                    # ä¿æŠ¤ï¼šé˜²æ­¢å¸§æ•°è¶Šç•Œ
                    if i >= len(self.timestamps): break
                    
                    # ä½¿ç”¨æ¯ä¸€å¸§å„è‡ªçš„çœŸå®æ—¶é—´æˆ³
                    ts_str = self.timestamps[i].strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
                    
                    db_rows.append((
                        username ,"webcam_stream", img_h, img_w, action_name,
                        float(box[0]), float(box[1]), float(box[2]), float(box[3]),
                        confidence, ts_str
                    ))
                    
        return db_rows

# ==========================================
# 1. å®šä¹‰å…¨å±€å…±äº«èµ„æºç±»
# ==========================================
class GlobalContext:
    def __init__(self):
        self.frame_queue = queue.Queue(maxsize=100)
        self.action_queue = queue.Queue(maxsize=10)
        self.db_queue = queue.Queue(maxsize=500)
        self.lock = threading.Lock()
        self.last_sample_time = 0
        self.results = {
            "action": "ç³»ç»Ÿåˆå§‹åŒ–...",
            "confidence": 0.0,
            "history": deque(maxlen=10),
            "last_update": time.time(),
            "status": "normal",
            "error_msg": ""
        }
        self.worker_running = False
        self.db_worker_running = False

@st.cache_resource
def get_context():
    return GlobalContext()

ctx = get_context()

# ==========================================
# 2. é¡µé¢é…ç½®ä¸ä¾§è¾¹æ é€»è¾‘
# ==========================================
st.set_page_config(layout="wide", page_title="å®æ—¶ç›‘æ§åŠ å¼ºç‰ˆ")

defaults = {
    'od_model_name': None,
    'ar_model_name': None,
    'od_conf': 0.5,
    'od_iou': 0.7,
    'last_saved_od_model': None,
    'last_saved_ar_model': None,
    'is_queue_cleared': False
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

os.makedirs(config.OD_MODEL_DIR, exist_ok=True)
os.makedirs(config.AR_MODEL_DIR, exist_ok=True)
os.makedirs(os.path.dirname(config.TEST_DATABASE), exist_ok=True)

with st.sidebar:
    st.write(f"å½“å‰ç”¨æˆ·: {st.session_state.user_info['username']}")
    st.header("âš™ï¸ æ¨¡å‹è®¾ç½®é¢æ¿")
    with st.expander("âš™ï¸ ç›®æ ‡æ£€æµ‹ (OD) è®¾ç½®", expanded=True):
        st.session_state.od_conf = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, st.session_state.od_conf, 0.05)
        st.session_state.od_iou = st.slider("IoU é˜ˆå€¼", 0.0, 1.0, st.session_state.od_iou, 0.05)
        od_files = [f for f in os.listdir(config.OD_MODEL_DIR) if f.endswith(('.pt', '.onnx'))]
        index_od = 0
        if st.session_state.od_model_name in od_files:
            index_od = od_files.index(st.session_state.od_model_name)
        elif od_files:
            st.session_state.od_model_name = od_files[0]
        st.session_state.od_model_name = st.selectbox("é€‰æ‹© OD æƒé‡æ–‡ä»¶", od_files if od_files else ["æ— å¯ç”¨æ¨¡å‹"], index=index_od)
        uploaded_od = st.file_uploader("â¬†ï¸ ä¸Šä¼  OD æ¨¡å‹ (.pt)", type=["pt", "onnx"])
        if uploaded_od and uploaded_od.name != st.session_state.last_saved_od_model:
            save_uploaded_od_model(uploaded_od)
            st.session_state.last_saved_od_model = uploaded_od.name
            st.rerun()
        if st.button("ğŸ”„ åˆ·æ–° OD ç¼“å­˜"):
            load_od_model_cached.clear()
            st.toast("OD ç¼“å­˜å·²æ¸…é™¤")

    with st.expander("âš™ï¸ è¡Œä¸ºè¯†åˆ« (AR) è®¾ç½®", expanded=True):
        ar_dirs = [d for d in os.listdir(config.AR_MODEL_DIR) if os.path.isdir(os.path.join(config.AR_MODEL_DIR, d))]
        index_ar = 0
        if st.session_state.ar_model_name in ar_dirs:
            index_ar = ar_dirs.index(st.session_state.ar_model_name)
        elif ar_dirs:
            st.session_state.ar_model_name = ar_dirs[0]
        st.session_state.ar_model_name = st.selectbox("é€‰æ‹© AR æ¨¡å‹å¥—ä»¶", ar_dirs if ar_dirs else ["æ— å¯ç”¨æ¨¡å‹"], index=index_ar)
        uploaded_ar = st.file_uploader("â¬†ï¸ ä¸Šä¼  AR å¥—ä»¶ (.py + .pth)", type=["pth", "py"], accept_multiple_files=True)
        if uploaded_ar:
            if len(uploaded_ar) == 2:
                current_fp = "|".join(sorted([f.name for f in uploaded_ar]))
                if current_fp != st.session_state.last_saved_ar_model:
                    save_uploaded_ar_model(uploaded_ar)
                    st.session_state.last_saved_ar_model = current_fp
                    st.rerun()
        if st.button("ğŸ”„ åˆ·æ–° AR ç¼“å­˜"):
            load_ar_model_cached.clear()
            st.toast("AR ç¼“å­˜å·²æ¸…é™¤")
    st.divider()
    device = st.selectbox("æ¨ç†è®¾å¤‡", ["cuda:0", "cpu"], index=0)

# ==========================================
# 3. åŠ¨æ€åŠ è½½æ¨¡å‹
# ==========================================
od_model = None
pred_args = {}
ar_model = None
ar_pipeline = None

if st.session_state.od_model_name and st.session_state.od_model_name != "æ— å¯ç”¨æ¨¡å‹":
    try:
        od_path = os.path.join(config.OD_MODEL_DIR, st.session_state.od_model_name)
        od_model, pred_args = load_od_model_cached(model_path=od_path, device=device, conf=st.session_state.od_conf, iou=st.session_state.od_iou)
    except Exception as e:
        st.error(f"OD æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

if st.session_state.ar_model_name and st.session_state.ar_model_name != "æ— å¯ç”¨æ¨¡å‹":
    try:
        ar_base = os.path.join(config.AR_MODEL_DIR, st.session_state.ar_model_name)
        pth_path = os.path.join(ar_base, st.session_state.ar_model_name + ".pth")
        cfg_path = os.path.join(ar_base, st.session_state.ar_model_name + ".py")
        ar_model, ar_pipeline, _ = load_ar_model_cached(pth_path=pth_path, cfg_path=cfg_path, device=device)
    except Exception as e:
        st.error(f"AR æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

# ==========================================
# 4. å…¨å±€å¸¸é‡ä¸ Worker
# ==========================================
SAMPLE_INTERVAL = 0.2
BATCH_SIZE = 16
PLAYBACK_DELAY = 0.1
ACTION_CLASSES = ["æ­£å¸¸è¡Œèµ°", "æ­£åœ¨è·‘æ­¥", "è·Œå€’æ£€æµ‹", "æŒ¥æ‰‹æ±‚æ•‘", "é™æ­¢ç«™ç«‹", "éæ³•å…¥ä¾µ"]

# === æ–°å¢ï¼šæ•°æ®åº“å†™å…¥çº¿ç¨‹ ===
def db_writer_worker():
    logger.info("æ•°æ®åº“å†™å…¥çº¿ç¨‹å¯åŠ¨")
    print(">>> ğŸ’¾ æ•°æ®åº“å†™å…¥çº¿ç¨‹å·²å¯åŠ¨ <<<")
    global ctx
    
    conn = sqlite3.connect(config.TEST_DATABASE, check_same_thread=False)
    cursor = conn.cursor()
    
    try:
        # ç»Ÿä¸€ç»“æœè¡¨ï¼šåŒ…å« OD å’Œ AR ç»“æœ
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS recognition_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_name TEXT,
                filename TEXT,
                height INTEGER,
                width INTEGER,
                category TEXT,
                bbox_x1 REAL,
                bbox_y1 REAL,
                bbox_x2 REAL,
                bbox_y2 REAL,
                confidence REAL,
                timestamp TEXT 
            )
        ''')
        conn.commit()
    except Exception as e:
        logger.error(f"æ•°æ®åº“åˆå§‹åŒ–é”™è¯¯: {e}")
        print(f"DB Init Error: {e}")

    while True:
        try:
            # 1. é˜»å¡ç­‰å¾…æ•°æ®
            data_batch = ctx.db_queue.get()
            # 2. æ‰¹é‡æ’å…¥
            cursor.executemany('''
                INSERT INTO recognition_results (user_name, filename, height, width, category, bbox_x1, bbox_y1, bbox_x2, bbox_y2, confidence, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', data_batch)
            conn.commit()
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“å†™å…¥é”™è¯¯: {e}")
            print(f"DB Write Error: {e}")
            time.sleep(1)

if not ctx.db_worker_running:
    t_db = threading.Thread(target=db_writer_worker, daemon=True)
    t_db.start()
    ctx.db_worker_running = True

def complex_worker():
    logger.info("åå°è¡Œä¸ºè¯†åˆ«çº¿ç¨‹å¯åŠ¨")
    print(">>> ğŸŸ¢ åå°è¡Œä¸ºè¯†åˆ«çº¿ç¨‹å·²å¯åŠ¨ <<<")
    global ctx, ar_model, ar_pipeline 
    
    while True:
        try:
            # buffer åŒ…å« (frame, timestamp, username)
            track_result, buffer, username = ctx.action_queue.get()
            
            # åˆ†ç¦»å¸§å’Œæ—¶é—´æˆ³
            frames = [b[0] for b in buffer]
            timestamps = [b[1] for b in buffer]
            
            if ar_model is None or ar_pipeline is None:
                ctx.results["action"] = "ç­‰å¾… AR æ¨¡å‹..."
                continue

            # åˆå§‹åŒ– OVDï¼Œä¼ å…¥æ—¶é—´æˆ³
            online_video_data = OnlineVideoData(frames, timestamps)
            online_video_data.load_cpu_data(track_result)
            
            ar_box = filter_and_analyze_tracking_results(
                boxes_list=online_video_data.boxes,
                track_ids_list=online_video_data.id,
                class_ids_list=online_video_data.cls,
                non_target_odcls=[],
                id_num_threshold=8
            )
            for k,v in ar_box.items():
                online_video_data.ar_box.append(v)
                online_video_data.ar_id.append(k)
            
            if len(online_video_data.ar_box) > 0:
                video_roi = process_video_regions(
                    frames=online_video_data.frames, 
                    detections=online_video_data.ar_box
                )
                preds = inference_recognizer_simplified(ar_model, video_roi, ar_pipeline)
                online_video_data.from_mmaction_result(preds)
                action = online_video_data.ar_cls.__str__()
                conf_val = online_video_data.ar_conf.__str__()
                
                # === ç”Ÿæˆç»Ÿä¸€çš„ DB æ•°æ® (å…³é”®ä¿®æ”¹) ===
                unified_db_data = online_video_data.get_unified_db_data(ACTION_CLASSES, username)
                
                # === æ¨é€è‡³ DB é˜Ÿåˆ— ===
                if unified_db_data and not ctx.db_queue.full():
                    ctx.db_queue.put(unified_db_data)

            else:
                action = "æ— ç›®æ ‡"
                conf_val = "0.0"

            timestamp = time.strftime("%H:%M:%S")
            ctx.results["action"] = action
            ctx.results["confidence"] = conf_val
            ctx.results["last_update"] = time.time()
            ctx.results["history"].append(f"{timestamp}: {action}")
            ctx.results["status"] = "normal"
            logger.info(f"åå°å®Œæˆåˆ†æ: {action}")
            print(f"åå°å®Œæˆåˆ†æ: {action}")
            
        except Exception as e:
            print("\n" + "="*50)
            logger.error(f"åå° Worker çº¿ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
            print(">>> âŒ åå° Worker çº¿ç¨‹å‘ç”Ÿå¼‚å¸¸ï¼")
            traceback.print_exc() 
            print("="*50 + "\n")
            ctx.results["status"] = "error"
            ctx.results["error_msg"] = str(e) 
            time.sleep(1)

if not ctx.worker_running:
    t = threading.Thread(target=complex_worker, daemon=True)
    t.start()
    ctx.worker_running = True
    logger.info("åå°è¡Œä¸ºè¯†åˆ«çº¿ç¨‹å·²å¯åŠ¨")
    print("--- çº¿ç¨‹åˆå§‹åŒ–å®Œæˆ ---")

# ==========================================
# 5. WebRTC ä¸ æ¨¡æ‹Ÿæ£€æµ‹
# ==========================================
def video_frame_callback(frame):
    # é‡‡é›†å½“å‰æ—¶é—´ (datetimeå¯¹è±¡)
    current_dt = datetime.datetime.now()
    img = frame.to_ndarray(format="bgr24")
    
    current_time_float = current_dt.timestamp() 
    
    with ctx.lock:
        if current_time_float - ctx.last_sample_time >= SAMPLE_INTERVAL:
            if not ctx.frame_queue.full():
                # å­˜å…¥å…ƒç»„ï¼š(å›¾ç‰‡, é‡‡é›†æ—¶é—´)
                ctx.frame_queue.put((img, current_dt))
                ctx.last_sample_time = current_time_float
    
    return av.VideoFrame.from_ndarray(img, format="bgr24")

def mock_detect(buffer_with_ts) -> tuple[list, list]:
    global od_model, pred_args
    
    # ä» buffer ä¸­æå–ä»…å›¾ç‰‡éƒ¨åˆ†ç”¨äº YOLO
    frames = [item[0] for item in buffer_with_ts]
    
    if od_model is None:
        return frames, []
        
    result = od_model.track(frames, persist=True, **pred_args)
    processed_frames = []
    for res in result:
        processed_frames.append(res.plot())
    return processed_frames, result

# ==========================================
# 6. ä¸» UI
# ==========================================
st.title("âœ… ç¨³å®šä¿®å¤ç‰ˆï¼šç»Ÿä¸€æ•°æ®åº“ç»“æœ")

c1, c2 = st.columns(2)

with c1:
    st.subheader("å®æ—¶è¾“å…¥ç”»é¢")
    webrtc_ctx = webrtc_streamer(
        key="stable-stream", 
        video_frame_callback=video_frame_callback,
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True
    )
    status = st.empty()

with c2:
    st.subheader("åˆ†æç»“æœç›‘æ§")
    monitor_ph = st.empty()
    st.divider()
    k1, k2 = st.columns(2)
    act_disp = k1.empty()
    conf_disp = k2.empty()

st.markdown("#### ğŸ“œ è¡Œä¸ºè¯†åˆ«ç»“æœ(å®æ—¶æ›´æ–°)")
hist_ph = st.empty()
error_ph = st.empty()

# ==========================================
# 7. ä¸»å¾ªç¯
# ==========================================
buffer = [] # æ­¤æ—¶ buffer å­˜çš„æ˜¯ (frame, timestamp)

if ctx.worker_running: 
    # status = st.empty()
    
    if webrtc_ctx.state.playing:
        if not st.session_state.get("_stream_logging_flag"):
            logger.info("å¼€å¯æ‘„åƒå¤´")
            st.session_state._stream_logging_flag = True
        status.empty()
        
        if not st.session_state.is_queue_cleared:
            status.text("ğŸ§¹ æ­£åœ¨æ¸…ç†ç¼“å­˜...")
            with ctx.lock:
                while not ctx.frame_queue.empty():
                    try: ctx.frame_queue.get_nowait()
                    except: pass
                while not ctx.action_queue.empty():
                    try: ctx.action_queue.get_nowait()
                    except: pass
                while not ctx.db_queue.empty():
                    try: ctx.db_queue.get_nowait()
                    except: pass
            st.session_state.is_queue_cleared = True
    
        while True:
            if ctx.results.get("status") == "error":
                error_ph.error(f"âŒ åå°æœåŠ¡å‘ç”Ÿä¸¥é‡é”™è¯¯: {ctx.results.get('error_msg', 'æœªçŸ¥é”™è¯¯')}")
                break

            try:
                item = ctx.frame_queue.get(timeout=1.0) # item æ˜¯ (img, ts)
                buffer.append(item)
                status.text(f"ğŸ“· æ­£åœ¨ç¼“å†²æ•°æ®: {len(buffer)}/{BATCH_SIZE}")
            except queue.Empty:
                if not webrtc_ctx.state.playing:
                    break
                continue
                
            if len(buffer) == BATCH_SIZE:
                status.text("âš¡ æ­£åœ¨å¤„ç†æ‰¹æ¬¡...")
                processed, track_result = mock_detect(buffer)

                if od_model is None:
                    ctx.results["action"] = "âš ï¸ OD æ¨¡å‹æœªåŠ è½½"
                elif not ctx.action_queue.full() and track_result:
                    clean_track_data = extract_yolo_data_to_cpu(track_result)
                    # ä¼ å…¥ buffer (åŒ…å«æ—¶é—´æˆ³)
                    current_username = st.session_state.user_info["username"]
                    ctx.action_queue.put((clean_track_data, copy.deepcopy(buffer), current_username))
                
                for img in processed:
                    monitor_ph.image(img, width="stretch", caption="Analysis View", channels="BGR")
                    curr = ctx.results
                    act_disp.metric("å½“å‰è¡Œä¸º", curr["action"])
                    conf_disp.metric("ç½®ä¿¡åº¦", curr['confidence'])
                    
                    history_text = ""
                    for h in reversed(list(curr["history"])):
                        history_text += f"- {h}\n"
                    if history_text:
                        hist_ph.markdown(history_text)
                    time.sleep(PLAYBACK_DELAY)
                
                buffer = []
                status.text("ğŸŸ¢ ç­‰å¾…ä¸‹ä¸€æ‰¹æ•°æ®...")
    else:
        status.info("ğŸ‘‹ ç³»ç»Ÿå°±ç»ªï¼Œè¯·ç‚¹å‡» START å¼€å¯æ‘„åƒå¤´è¿›è¡Œåˆ†æ")
        st.session_state.is_queue_cleared = False
        st.session_state._stream_logging_flag = False