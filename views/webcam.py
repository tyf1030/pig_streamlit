import streamlit as st
from streamlit_webrtc import webrtc_streamer
import av
import cv2
import threading
import time
import queue
import random
import os
import shutil
from collections import deque
import numpy as np
import copy
import traceback

# å¼•å…¥é¡¹ç›®é…ç½®
import config 
from utils.model_loader import load_ar_model_cached, load_od_model_cached
from backend.processors import filter_and_analyze_tracking_results, process_video_regions
from backend.inference import inference_recognizer_simplified

# ==========================================
# 0. è¾…åŠ©å·¥å…·å‡½æ•°
# ==========================================
def extract_yolo_data_to_cpu(yolo_results: list) -> list:
    """
    å°† YOLO ç»“æœè½¬æ¢ä¸º CPU ä¸Šçš„ numpy å­—å…¸åˆ—è¡¨ï¼Œä¾¿äºè·¨çº¿ç¨‹ä¼ é€’ã€‚
    ä¿®å¤ï¼šç¡®ä¿ ids é•¿åº¦ä¸ boxes æ•°é‡ä¸€è‡´ï¼Œé˜²æ­¢ "boolean index did not match" å´©æºƒã€‚
    """
    cpu_data = []
    for res in yolo_results:
        # 1. è·å–å½“å‰å¸§æ£€æµ‹åˆ°çš„æ¡†çš„æ•°é‡
        n_boxes = len(res.boxes)
        
        # 2. å¤„ç† ID
        if res.boxes.id is not None:
            # æ­£å¸¸æƒ…å†µï¼šæœ‰ IDï¼Œç›´æ¥å–ç”¨
            ids = res.boxes.id.cpu().numpy()
        else:
            # å¼‚å¸¸æƒ…å†µï¼šæœ‰æ¡†ä½†æ—  ID (å¦‚åˆšå¼€å§‹æ£€æµ‹æ—¶)ï¼Œæˆ–è€…æ— æ¡†
            # å¿…é¡»ç”Ÿæˆä¸€ä¸ªé•¿åº¦ä¸º n_boxes çš„æ•°ç»„ï¼Œå¦åˆ™åç»­è¿‡æ»¤æ—¶ä¼šæŠ¥é”™
            if n_boxes > 0:
                # ç”Ÿæˆå…¨æ˜¯ -1 çš„æ•°ç»„ï¼Œè¡¨ç¤ºæš‚æ—  ID
                ids = np.full((n_boxes,), -1.0) 
            else:
                # æ²¡æœ‰æ¡†ï¼ŒID ä¹Ÿæ˜¯ç©ºçš„
                ids = np.array([])

        frame_data = {
            "boxes": res.boxes.xyxy.cpu().numpy(),
            "conf": res.boxes.conf.cpu().numpy(),
            "cls": res.boxes.cls.cpu().numpy(),
            "id": ids # è¿™é‡Œçš„é•¿åº¦ç°åœ¨ä¸¥æ ¼ç­‰äº boxes çš„é•¿åº¦
        }
        cpu_data.append(frame_data)
    return cpu_data

def save_uploaded_od_model(uploaded_file):
    """ä¿å­˜ä¸Šä¼ çš„ OD æ¨¡å‹"""
    if uploaded_file is None: return
    # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
    os.makedirs(config.OD_MODEL_DIR, exist_ok=True)
    save_path = os.path.join(config.OD_MODEL_DIR, uploaded_file.name)
    with open(save_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    st.toast(f"âœ… OD æ¨¡å‹å·²ä¿å­˜: {uploaded_file.name}")

def save_uploaded_ar_model(uploaded_files):
    """ä¿å­˜ä¸Šä¼ çš„ AR æ¨¡å‹å¥—ä»¶"""
    if not uploaded_files: return
    
    py_file = next((f for f in uploaded_files if f.name.endswith('.py')), None)
    pth_file = next((f for f in uploaded_files if f.name.endswith('.pth')), None)
    
    if not py_file or not pth_file:
        st.error("âŒ å¿…é¡»è¦åŒæ—¶ä¸Šä¼  .py å’Œ .pth æ–‡ä»¶")
        return

    py_name = os.path.splitext(py_file.name)[0]
    pth_name = os.path.splitext(pth_file.name)[0]
    
    if py_name != pth_name:
        st.error(f"âŒ æ–‡ä»¶åä¸ä¸€è‡´: {py_name}.py vs {pth_name}.pth")
        return

    model_dir = os.path.join(config.AR_MODEL_DIR, py_name)
    os.makedirs(model_dir, exist_ok=True)
    
    with open(os.path.join(model_dir, py_file.name), "wb") as f:
        f.write(py_file.getbuffer())
    with open(os.path.join(model_dir, pth_file.name), "wb") as f:
        f.write(pth_file.getbuffer())
        
    st.toast(f"âœ… AR æ¨¡å‹å·²ä¿å­˜è‡³: {model_dir}")

class OnlineVideoData:
    def __init__(self, frames:list):
        self.frames = frames
        self.boxes = []
        self.conf = []
        self.cls = []
        self.id = []
        # ... å…¶ä»–åˆå§‹åŒ– ...
        self.ar_box = []
        self.ar_id = []
        self.ar_conf = []
        self.ar_cls = []
    
    def load_cpu_data(self, cpu_results: list):
        for result in cpu_results:
            self.boxes.append(result["boxes"])
            self.conf.append(result["conf"])
            self.cls.append(result["cls"])
            self.id.append(result["id"])
    
    def from_mmaction_result(self, mm_res:list):
        for result in mm_res:
            scores = result.pred_score.cpu().numpy()
            self.ar_conf.append(np.max(scores))
            self.ar_cls.append(np.argmax(scores))

# ==========================================
# 1. å®šä¹‰å…¨å±€å…±äº«èµ„æºç±» (å•ä¾‹æ¨¡å¼)
# ==========================================
class GlobalContext:
    def __init__(self):
        self.frame_queue = queue.Queue(maxsize=100)
        self.action_queue = queue.Queue(maxsize=10)
        self.lock = threading.Lock()
        self.last_sample_time = 0
        self.results = {
            "action": "ç³»ç»Ÿåˆå§‹åŒ–...",
            "confidence": 0.0,
            "history": deque(maxlen=10),
            "last_update": time.time(),
            "status": "normal",
            "error_msg": ""
        }
        self.worker_running = False

@st.cache_resource
def get_context():
    return GlobalContext()

ctx = get_context()

# ==========================================
# 2. é¡µé¢é…ç½®ä¸ä¾§è¾¹æ é€»è¾‘ (ç§»æ¤è‡ª new_app.py)
# ==========================================
st.set_page_config(layout="wide", page_title="å®æ—¶ç›‘æ§åŠ å¼ºç‰ˆ")

# --- åˆå§‹åŒ– Session State ---
defaults = {
    'od_model_name': None,
    'ar_model_name': None,
    'od_conf': 0.5,
    'od_iou': 0.7,
    'last_saved_od_model': None,
    'last_saved_ar_model': None,
    'is_queue_cleared': False  # æ–°å¢ï¼šç”¨äºæ§åˆ¶é‡å¯æ—¶çš„é˜Ÿåˆ—æ¸…ç†
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(config.OD_MODEL_DIR, exist_ok=True)
os.makedirs(config.AR_MODEL_DIR, exist_ok=True)

# --- ä¾§è¾¹æ  UI ---
with st.sidebar:
    st.header("âš™ï¸ æ¨¡å‹è®¾ç½®é¢æ¿")
    
    # 1. ç›®æ ‡æ£€æµ‹å‚æ•°
    with st.expander("âš™ï¸ ç›®æ ‡æ£€æµ‹ (OD) è®¾ç½®", expanded=True):
        st.session_state.od_conf = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, st.session_state.od_conf, 0.05)
        st.session_state.od_iou = st.slider("IoU é˜ˆå€¼", 0.0, 1.0, st.session_state.od_iou, 0.05)
        
        # æ‰«ææ¨¡å‹æ–‡ä»¶
        od_files = [f for f in os.listdir(config.OD_MODEL_DIR) if f.endswith(('.pt', '.onnx'))]
        
        # è‡ªåŠ¨é€‰æ‹©é€»è¾‘
        index_od = 0
        if st.session_state.od_model_name in od_files:
            index_od = od_files.index(st.session_state.od_model_name)
        elif od_files:
            st.session_state.od_model_name = od_files[0]
            
        st.session_state.od_model_name = st.selectbox(
            "é€‰æ‹© OD æƒé‡æ–‡ä»¶", 
            od_files if od_files else ["æ— å¯ç”¨æ¨¡å‹"],
            index=index_od
        )
        
        # ä¸Šä¼ 
        uploaded_od = st.file_uploader("â¬†ï¸ ä¸Šä¼  OD æ¨¡å‹ (.pt)", type=["pt", "onnx"])
        if uploaded_od and uploaded_od.name != st.session_state.last_saved_od_model:
            save_uploaded_od_model(uploaded_od)
            st.session_state.last_saved_od_model = uploaded_od.name
            st.rerun()

        if st.button("ğŸ”„ åˆ·æ–° OD ç¼“å­˜"):
            load_od_model_cached.clear()
            st.toast("OD ç¼“å­˜å·²æ¸…é™¤")

    # 2. è¡Œä¸ºè¯†åˆ«å‚æ•°
    with st.expander("âš™ï¸ è¡Œä¸ºè¯†åˆ« (AR) è®¾ç½®", expanded=True):
        ar_dirs = [d for d in os.listdir(config.AR_MODEL_DIR) if os.path.isdir(os.path.join(config.AR_MODEL_DIR, d))]
        
        # è‡ªåŠ¨é€‰æ‹©é€»è¾‘
        index_ar = 0
        if st.session_state.ar_model_name in ar_dirs:
            index_ar = ar_dirs.index(st.session_state.ar_model_name)
        elif ar_dirs:
            st.session_state.ar_model_name = ar_dirs[0]

        st.session_state.ar_model_name = st.selectbox(
            "é€‰æ‹© AR æ¨¡å‹å¥—ä»¶", 
            ar_dirs if ar_dirs else ["æ— å¯ç”¨æ¨¡å‹"],
            index=index_ar
        )
        
        # ä¸Šä¼ 
        uploaded_ar = st.file_uploader(
            "â¬†ï¸ ä¸Šä¼  AR å¥—ä»¶ (.py + .pth)", 
            type=["pth", "py"], 
            accept_multiple_files=True
        )
        if uploaded_ar:
            if len(uploaded_ar) == 2:
                current_fp = "|".join(sorted([f.name for f in uploaded_ar]))
                if current_fp != st.session_state.last_saved_ar_model:
                    save_uploaded_ar_model(uploaded_ar)
                    st.session_state.last_saved_ar_model = current_fp
                    st.rerun()

        if st.button("ğŸ”„ åˆ·æ–° AR ç¼“å­˜"):
            load_ar_model_cached.clear()
            st.toast("AR ç¼“å­˜å·²æ¸…é™¤")
            
    st.divider()
    device = st.selectbox("æ¨ç†è®¾å¤‡", ["cuda:0", "cpu"], index=0)

# ==========================================
# 3. åŠ¨æ€åŠ è½½æ¨¡å‹
# ==========================================
od_model = None
pred_args = {}
ar_model = None
ar_pipeline = None

# åŠ è½½ OD æ¨¡å‹
if st.session_state.od_model_name and st.session_state.od_model_name != "æ— å¯ç”¨æ¨¡å‹":
    try:
        od_path = os.path.join(config.OD_MODEL_DIR, st.session_state.od_model_name)
        od_model, pred_args = load_od_model_cached(
            model_path=od_path, 
            device=device, 
            conf=st.session_state.od_conf, 
            iou=st.session_state.od_iou
        )
    except Exception as e:
        st.error(f"OD æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

# åŠ è½½ AR æ¨¡å‹
if st.session_state.ar_model_name and st.session_state.ar_model_name != "æ— å¯ç”¨æ¨¡å‹":
    try:
        ar_base = os.path.join(config.AR_MODEL_DIR, st.session_state.ar_model_name)
        # å‡è®¾æ–‡ä»¶åä¸æ–‡ä»¶å¤¹åä¸€è‡´ï¼Œè¿™æ˜¯ new_app.py çš„é€»è¾‘
        pth_path = os.path.join(ar_base, st.session_state.ar_model_name + ".pth")
        cfg_path = os.path.join(ar_base, st.session_state.ar_model_name + ".py")
        ar_model, ar_pipeline, _ = load_ar_model_cached(
            pth_path=pth_path, 
            cfg_path=cfg_path, 
            device=device
        )
    except Exception as e:
        st.error(f"AR æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

# ==========================================
# 4. å…¨å±€å¸¸é‡ä¸ Worker
# ==========================================
SAMPLE_INTERVAL = 0.2
BATCH_SIZE = 16
PLAYBACK_DELAY = 0.1

def complex_worker():
    print(">>> ğŸŸ¢ åå°è¡Œä¸ºè¯†åˆ«çº¿ç¨‹å·²å¯åŠ¨ <<<")
    # å¼•ç”¨å…¨å±€å˜é‡ï¼Œæ³¨æ„ï¼šå½“ä¸»çº¿ç¨‹æ›´æ”¹æ¨¡å‹æ—¶ï¼Œè¿™é‡Œä¸‹æ¬¡å¾ªç¯ä¼šè¯»å–åˆ°æ–°çš„å…¨å±€å¯¹è±¡
    global ctx, ar_model, ar_pipeline 
    
    while True:
        try:
            track_result, frames = ctx.action_queue.get()
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å°±ç»ª
            if ar_model is None or ar_pipeline is None:
                # æ¨¡å‹æœªåŠ è½½æ—¶è·³è¿‡æ¨ç†ï¼Œé¿å…å´©æºƒ
                # æ›´æ–°çŠ¶æ€ä½†ä¸æŠ¥é”™ï¼Œå› ä¸ºç”¨æˆ·å¯èƒ½æ­£åœ¨åˆ‡æ¢æ¨¡å‹
                ctx.results["action"] = "ç­‰å¾… AR æ¨¡å‹..."
                continue

            online_video_data = OnlineVideoData(frames)
            online_video_data.load_cpu_data(track_result)
            
            # åå¤„ç†é€»è¾‘
            ar_box = filter_and_analyze_tracking_results(
                boxes_list=online_video_data.boxes,
                track_ids_list=online_video_data.id,
                class_ids_list=online_video_data.cls,
                non_target_odcls=[],
                id_num_threshold=8
            )
            for k,v in ar_box.items():
                online_video_data.ar_box.append(v)
                online_video_data.ar_id.append(k)
            
            # åªæœ‰å½“æœ‰æ£€æµ‹åˆ°ç›®æ ‡æ—¶æ‰è¿›è¡Œ AR æ¨ç†
            if len(online_video_data.ar_box) > 0:
                video_roi = process_video_regions(
                    frames=online_video_data.frames, 
                    detections=online_video_data.ar_box
                )
                preds = inference_recognizer_simplified(ar_model, video_roi, ar_pipeline)
                online_video_data.from_mmaction_result(preds)
                action = online_video_data.ar_cls.__str__()
                conf_val = online_video_data.ar_conf.__str__()
            else:
                action = "æ— ç›®æ ‡"
                conf_val = "0.0"

            timestamp = time.strftime("%H:%M:%S")
            ctx.results["action"] = action
            ctx.results["confidence"] = conf_val
            ctx.results["last_update"] = time.time()
            ctx.results["history"].append(f"{timestamp}: {action}")
            ctx.results["status"] = "normal" # æ¢å¤æ­£å¸¸çŠ¶æ€
            
            print(f"åå°å®Œæˆåˆ†æ: {action}")
            
        except Exception as e:
            # å®Œæ•´çš„é”™è¯¯å †æ ˆæ‰“å°
            print("\n" + "="*50)
            print(">>> âŒ åå° Worker çº¿ç¨‹å‘ç”Ÿå¼‚å¸¸ï¼")
            print(f">>> é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f">>> é”™è¯¯è¯¦æƒ…: {e}")
            print("-" * 20 + " å®Œæ•´å †æ ˆ " + "-" * 20)
            traceback.print_exc() 
            print("="*50 + "\n")
            
            # æ›´æ–°å…¨å±€çŠ¶æ€ (UIæ˜¾ç¤ºç”¨)
            ctx.results["status"] = "error"
            ctx.results["error_msg"] = str(e) 
            
            time.sleep(1)

# å¯åŠ¨çº¿ç¨‹
if not ctx.worker_running:
    t = threading.Thread(target=complex_worker, daemon=True)
    t.start()
    ctx.worker_running = True
    print("--- çº¿ç¨‹åˆå§‹åŒ–å®Œæˆ ---")

# ==========================================
# 5. WebRTC ä¸ æ¨¡æ‹Ÿæ£€æµ‹
# ==========================================
def video_frame_callback(frame):
    current_time = time.time()
    img = frame.to_ndarray(format="bgr24")
    
    with ctx.lock:
        if current_time - ctx.last_sample_time >= SAMPLE_INTERVAL:
            if not ctx.frame_queue.full():
                ctx.frame_queue.put(img)
                ctx.last_sample_time = current_time
    
    return av.VideoFrame.from_ndarray(img, format="bgr24")

def mock_detect(frames) -> tuple[list, list]:
    global od_model, pred_args
    
    # ä¿æŠ¤é€»è¾‘ï¼šå¦‚æœæ²¡æœ‰æ¨¡å‹ï¼ŒåŸæ ·è¿”å›
    if od_model is None:
        return frames, []
        
    result = od_model.track(frames, persist=True, **pred_args)
    processed_frames = []
    for res in result:
        processed_frames.append(res.plot())
    return processed_frames, result

# ==========================================
# 6. ä¸» UI
# ==========================================
st.title("âœ… ç¨³å®šä¿®å¤ç‰ˆï¼šå«ä¾§è¾¹æ æ§åˆ¶")

c1, c2 = st.columns(2)

with c1:
    st.subheader("æ‘„åƒå¤´è¾“å…¥")
    # æ¥æ”¶ webrtc_streamer è¿”å›çš„ä¸Šä¸‹æ–‡ï¼Œç”¨äºåˆ¤æ–­æ’­æ”¾çŠ¶æ€
    webrtc_ctx = webrtc_streamer(
        key="stable-stream", 
        video_frame_callback=video_frame_callback,
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True
    )

with c2:
    st.subheader("åˆ†æç»“æœç›‘æ§")
    monitor_ph = st.empty()
    st.divider()
    k1, k2 = st.columns(2)
    act_disp = k1.empty()
    conf_disp = k2.empty()

st.markdown("#### ğŸ“œ å†å²è®°å½• (å®æ—¶æ›´æ–°)")
hist_ph = st.empty()
error_ph = st.empty()

# ==========================================
# 7. ä¸»å¾ªç¯
# ==========================================
buffer = []

if ctx.worker_running: 
    status = st.empty()
    
    # åªæœ‰å½“æ‘„åƒå¤´æ­£åœ¨æ’­æ”¾æ—¶ï¼Œæ‰è¿›è¡Œå¤„ç†
    if webrtc_ctx.state.playing:
        status.empty() # æ’­æ”¾æ—¶éšè—æç¤º
        
        # === å¯åŠ¨æ¸…ç†é€»è¾‘ (é˜²æ­¢é‡å¯æ—¶å‡ºç°æ—§å¸§å †ç§¯) ===
        if not st.session_state.is_queue_cleared:
            status.text("ğŸ§¹ æ­£åœ¨æ¸…ç†ç¼“å­˜...")
            with ctx.lock:
                while not ctx.frame_queue.empty():
                    try: ctx.frame_queue.get_nowait()
                    except: pass
                while not ctx.action_queue.empty():
                    try: ctx.action_queue.get_nowait()
                    except: pass
            st.session_state.is_queue_cleared = True
            print(">>> é˜Ÿåˆ—å·²æ¸…ç©ºï¼Œå‡†å¤‡æ¥æ”¶æ–°ç”»é¢")
        # ===========================================
    
        while True:
            # é”™è¯¯æ£€æŸ¥
            if ctx.results.get("status") == "error":
                error_ph.error(f"âŒ åå°æœåŠ¡å‘ç”Ÿä¸¥é‡é”™è¯¯: {ctx.results.get('error_msg', 'æœªçŸ¥é”™è¯¯')}")
                # break # å‡ºé”™è·³å‡º

            # å°è¯•è·å–æ•°æ®
            try:
                # ä½¿ç”¨ timeout é¿å…æ­»é”ï¼ŒåŒæ—¶é…åˆ webrtc çŠ¶æ€é€€å‡º
                f = ctx.frame_queue.get(timeout=1.0)
                buffer.append(f)
                status.text(f"ğŸ“· æ­£åœ¨ç¼“å†²æ•°æ®: {len(buffer)}/{BATCH_SIZE}")
            except queue.Empty:
                # å¦‚æœæ‘„åƒå¤´å·²åœæ­¢ï¼Œè·³å‡ºå¾ªç¯
                if not webrtc_ctx.state.playing:
                    break
                continue
                
            # æ”’å¤Ÿ Batch å¤„ç†
            if len(buffer) == BATCH_SIZE:
                status.text("âš¡ æ­£åœ¨å¤„ç†æ‰¹æ¬¡...")
                
                # A. æ£€æµ‹
                processed, track_result = mock_detect(buffer)

                # B. å‘é€ç»™åå°
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½
                if od_model is None:
                    ctx.results["action"] = "âš ï¸ OD æ¨¡å‹æœªåŠ è½½"
                # æ­£å¸¸å‘é€
                elif not ctx.action_queue.full() and track_result:
                    clean_track_data = extract_yolo_data_to_cpu(track_result)
                    ctx.action_queue.put((clean_track_data, copy.deepcopy(buffer)))
                
                # C. å›æ”¾æ›´æ–°
                for img in processed:
                    monitor_ph.image(img, width="stretch", caption="Analysis View", channels="BGR")
                    
                    curr = ctx.results
                    act_disp.metric("å½“å‰è¡Œä¸º", curr["action"])
                    conf_disp.metric("ç½®ä¿¡åº¦", curr['confidence'])
                    
                    history_text = ""
                    for h in reversed(list(curr["history"])):
                        history_text += f"- {h}\n"
                    if history_text:
                        hist_ph.markdown(history_text)
                    
                    time.sleep(PLAYBACK_DELAY)
                
                buffer = []
                status.text("ğŸŸ¢ ç­‰å¾…ä¸‹ä¸€æ‰¹æ•°æ®...")
                
    else:
        # æ‘„åƒå¤´æœªå¼€å¯æ—¶çš„æ˜¾ç¤º
        status.info("ğŸ‘‹ ç³»ç»Ÿå°±ç»ªï¼Œè¯·ç‚¹å‡» START å¼€å¯æ‘„åƒå¤´è¿›è¡Œåˆ†æ")
        # é‡ç½®æ¸…ç†æ ‡è®°ï¼Œç¡®ä¿ä¸‹æ¬¡å¼€å¯æ—¶å†æ¬¡æ¸…ç†
        st.session_state.is_queue_cleared = False